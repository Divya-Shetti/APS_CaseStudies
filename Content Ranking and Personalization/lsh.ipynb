{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "class LSH:\n",
        "    def __init__(self, num_hashes, dim):\n",
        "        self.num_hashes = num_hashes\n",
        "        self.planes = np.random.randn(num_hashes, dim)  # Random hyperplanes\n",
        "\n",
        "    def hash(self, vector):\n",
        "        # Compute dot product with each plane and get 1 if >=0 else 0\n",
        "        return ''.join(['1' if np.dot(vector, plane) >= 0 else '0' for plane in self.planes])\n",
        "\n",
        "# Sample documents\n",
        "docs = [\n",
        "    \"the cat sat on the mat\",\n",
        "    \"the cat sat on a mat\",\n",
        "    \"dogs are in the yard\",\n",
        "    \"the quick brown fox jumps over the lazy dog\"\n",
        "]\n",
        "\n",
        "# Step 1: TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(docs).toarray()\n",
        "\n",
        "# Step 2: Hash documents using LSH\n",
        "lsh = LSH(num_hashes=10, dim=tfidf_matrix.shape[1])\n",
        "buckets = {}\n",
        "\n",
        "for idx, vec in enumerate(tfidf_matrix):\n",
        "    h = lsh.hash(vec)\n",
        "    if h not in buckets:\n",
        "        buckets[h] = []\n",
        "    buckets[h].append((idx, docs[idx]))\n",
        "\n",
        "# Step 3: Show buckets with near-duplicates\n",
        "print(\"Buckets with near-duplicate documents:\")\n",
        "for bucket, items in buckets.items():\n",
        "    if len(items) > 1:\n",
        "        print(f\"\\nBucket Hash: {bucket}\")\n",
        "        for i in items:\n",
        "            print(f\"Doc {i[0]}: {i[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMURXOHovC1u",
        "outputId": "13b2ada0-38ce-48ce-fbe8-faab7444907c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buckets with near-duplicate documents:\n",
            "\n",
            "Bucket Hash: 0010010101\n",
            "Doc 0: the cat sat on the mat\n",
            "Doc 1: the cat sat on a mat\n"
          ]
        }
      ]
    }
  ]
}